# scripts/migrate_r10_add_sources.py
from __future__ import annotations

import argparse
import os
import sys
from typing import Any

from src.db import get_conn


def _apply_dsn_override(dsn: str | None) -> None:
    if not dsn:
        return
    os.environ["DATABASE_URL"] = dsn
    os.environ["PG_DSN"] = dsn


def _table_exists(cur: Any, *, schema: str, table: str) -> bool:
    cur.execute("SELECT to_regclass(%s)", (f"{schema}.{table}",))
    row = cur.fetchone()
    return row is not None and row[0] is not None


def _col_exists(cur: Any, *, schema: str, table: str, col: str) -> bool:
    cur.execute(
        """
        SELECT 1
          FROM information_schema.columns
         WHERE table_schema = %s
           AND table_name = %s
           AND column_name = %s
         LIMIT 1
        """,
        (schema, table, col),
    )
    return cur.fetchone() is not None


def _index_exists(cur: Any, *, schema: str, name: str) -> bool:
    cur.execute("SELECT to_regclass(%s)", (f"{schema}.{name}",))
    row = cur.fetchone()
    return row is not None and row[0] is not None


def ensure_sources_table(cur: Any, *, schema: str) -> None:
    """
    Ensure 'sources' exists (idempotent), and add missing columns if needed.

    Original SQLite intent:
      - id INTEGER PRIMARY KEY AUTOINCREMENT
      - source_url TEXT UNIQUE NOT NULL
      - html BLOB NOT NULL
      - fetched_at INTEGER NOT NULL

    Postgres mapping:
      - id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY
      - source_url TEXT UNIQUE NOT NULL
      - html BYTEA NOT NULL
      - fetched_at BIGINT NOT NULL
    """
    if not _table_exists(cur, schema=schema, table="sources"):
        cur.execute(
            f"""
            CREATE TABLE {schema}."sources" (
                id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
                source_url TEXT UNIQUE NOT NULL,
                html BYTEA NOT NULL,
                fetched_at BIGINT NOT NULL
            )
            """.strip()
        )
    else:
        # If the table exists (potentially with a newer schema), only ensure the
        # legacy columns existâ€”do not attempt type coercion here.
        fq = f'{schema}."sources"'
        if not _col_exists(cur, schema=schema, table="sources", col="source_url"):
            cur.execute(f"ALTER TABLE {fq} ADD COLUMN source_url TEXT")
            # cannot safely force NOT NULL if existing rows; keep minimal/idempotent

        if not _col_exists(cur, schema=schema, table="sources", col="html"):
            cur.execute(f"ALTER TABLE {fq} ADD COLUMN html BYTEA")

        if not _col_exists(cur, schema=schema, table="sources", col="fetched_at"):
            cur.execute(f"ALTER TABLE {fq} ADD COLUMN fetched_at BIGINT")

    # Optional: lightweight index to speed up lookups by URL (unique already).
    # Keep the same behavior as the original script, but only if source_url exists.
    if _col_exists(cur, schema=schema, table="sources", col="source_url"):
        idx_name = "idx_sources_url"
        if not _index_exists(cur, schema=schema, name=idx_name):
            cur.execute(f'CREATE UNIQUE INDEX {idx_name} ON {schema}."sources"(source_url)')


def main() -> None:
    ap = argparse.ArgumentParser(
        description="R10 migration: ensure 'sources' table exists (PostgreSQL)."
    )
    ap.add_argument(
        "--dsn",
        "--db",
        dest="dsn",
        default=None,
        help="Postgres DSN/URL (optional; overrides DATABASE_URL/PG_DSN for this run).",
    )
    ap.add_argument(
        "--schema",
        default=os.getenv("PGSCHEMA", "public"),
        help="Target schema (default: public, or PGSCHEMA env var).",
    )
    args = ap.parse_args()
    _apply_dsn_override(args.dsn)

    conn = get_conn()
    try:
        cur = conn.cursor()
        try:
            ensure_sources_table(cur, schema=args.schema)
        finally:
            try:
                cur.close()
            except Exception:
                pass
        conn.commit()
    except Exception:
        try:
            conn.rollback()
        except Exception:
            pass
        raise
    finally:
        try:
            conn.close()
        except Exception:
            pass

    print("Migration complete. Ensured 'sources' table exists.")


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"ERROR: {e}", file=sys.stderr)
        raise
